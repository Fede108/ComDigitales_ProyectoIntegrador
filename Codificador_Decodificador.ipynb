{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Shift Chirp Modulation: La modulación LoRa\n",
    "\n",
    "LoRa emplea **Chirps** como base de cada símbolo modulado. Un **chirp** es una señal senoidal que aumenta o decrementa su frecuencia de forma lineal.\n",
    "\n",
    "\n",
    "Cada símbolo $s(nT_s)$ es un numero real que se genera a partir de un vector binario $w(nT_s)$ de longitud igual al **Spreading Factor** (SF), el cual puede tomar valores entre 7 y 12.\n",
    "\n",
    "\n",
    "- **Vector de bits**: $w(nT_s) = [w_0(nT_s), \\dots, w_{\\mathrm{SF}-1}(nT_s)]$, donde cada $w_h(nT_s) \\in \\{0, 1\\}$.  \n",
    "\n",
    "- **Combinaciones posibles**: este vector de $\\mathrm{SF}$ bits admite $2^{\\mathrm{SF}}$ símbolos distintos.\n",
    "\n",
    "\n",
    "\n",
    "Para convertir el vector binario $w(nT_s)$ a un valor real $s(nT_s)$, usamos la siguiente  ecuación propuesta en el paper de Vangelista:\n",
    "\n",
    "$$\n",
    "s(nT_s) \\;=\\; \\sum_{h=0}^{\\mathrm{SF}-1} w_h(nT_s)\\,\\cdot\\,2^{h}\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "* $w_h(nT_s)$ es el bit en la posición $h$ del vector de bits $w(nT_s)$.\n",
    "\n",
    "* Cada bit se multiplica por $2^h$ (su “peso”) y se suman todos los términos.\n",
    "\n",
    "\n",
    "Podemos ver entonces que el símbolo $s(nT_s)$ puede tomar cualquiera de los valores enteros:\n",
    "\n",
    "$$\n",
    "s(nT_s) \\;\\in\\; \\{\\,0, 1, 2, \\dots, 2^{\\mathrm{SF}} -1\\}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 1 0 0 0]\n",
      "[1 0 0 0 0 1 0 0 0]\n",
      "\n",
      "La Probabilidad de error en la decodificación es: 0.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_random_uniform_bits(sf, nb_samples, ref):\n",
    "    # Ajustamos nb_samples al múltiplo de sf más cercano por debajo\n",
    "    nb_samples_adj = (nb_samples // sf) * sf    \n",
    "\n",
    "    # Creamos un vector de numeros entre 0 y 1 con distribucion aleatoria\n",
    "    z = np.random.uniform(size=nb_samples_adj)\n",
    "\n",
    "    # Generamos los bits con una probabilidad a priori dada por ref\n",
    "    bits = (z > ref).astype(np.uint8)\n",
    "\n",
    "    return bits\n",
    "\n",
    "def encoder(bits, sf):\n",
    "    n_blocks = bits.size // sf\n",
    "    # Restructuramos los bits en bloques de sf bits\n",
    "    blocks = bits.reshape(n_blocks, sf)  \n",
    "\n",
    "    # Generamos un vector con los pesos de cada bit\n",
    "    weights = 2 ** np.arange(sf)[::-1]\n",
    "\n",
    "    # Producto punto entre bits y pesos\n",
    "    symbols = blocks.dot(weights)     \n",
    "\n",
    "    return symbols\n",
    "\n",
    "def decoder(symbols, sf):    \n",
    "    symbols = np.asarray(symbols, dtype=np.uint64)\n",
    "    # Preparamos un array vacío para los bits\n",
    "    n_blocks = symbols.size\n",
    "    bits = np.zeros((n_blocks, sf), dtype=np.uint8)\n",
    "\n",
    "    # Creamos copia para no modificar el original\n",
    "    vals = symbols.copy()\n",
    "    \n",
    "    # Empezamos por el bit menos significativo (LSB)\n",
    "    # y vamos subiendo hasta el sf-1, guardándolo en la columna correspondiente.\n",
    "    for i in range(sf):\n",
    "        # Gracias a NumPy, (vals % 2) y (vals //= 2) se ejecutan en paralelo sobre\n",
    "        # cada posición de vals, sin necesidad de bucle sobre símbolos.\n",
    "        bits[:, sf - 1 - i] = (vals % 2).astype(np.uint8)   \n",
    "        # Descartamos ese bit dividiendo por 2 (floor division)\n",
    "        vals //= 2\n",
    "\n",
    "    return bits\n",
    "\n",
    "def BER(enviados, recibidos, numberOfsamples, sf):\n",
    "    # Ajustamos al múltiplo de sf más cercano por debajo\n",
    "    nb_samples_adj = (numberOfsamples // sf) * sf\n",
    "     \n",
    "    # Aplanamos la matriz de recibidos a 1D\n",
    "    recibidos_flat = recibidos.flatten()[:nb_samples_adj]\n",
    "    \n",
    "    # Contamos diferencias y calculamos probabilidad de error\n",
    "    errores = np.sum(enviados != recibidos_flat)\n",
    "    pe = errores / nb_samples_adj\n",
    "    \n",
    "    print(f\"\\nLa Probabilidad de error en la decodificación es: {pe:.6f}\")\n",
    "    \n",
    "\n",
    "# Ejemplo de uso:\n",
    "SF = 9                     # puede ser cualquiera entre 7 y 12\n",
    "nb_samples = 10000\n",
    "bits_send = generate_random_uniform_bits(SF, nb_samples, 0.5)\n",
    "\n",
    "print(bits_send[:9])           # los primeros 9 bits\n",
    "\n",
    "bits_recv = decoder(encoder(bits_send, SF), SF)\n",
    "\n",
    "print(bits_recv[0])           # los primeros 9 bits\n",
    "\n",
    "BER(bits_send, bits_recv, nb_samples, SF)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
